<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>`sherlock`: Causal Machine Learning for Segment Discovery • sherlock</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="`sherlock`: Causal Machine Learning for Segment Discovery">
<meta property="og:description" content="sherlock">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">sherlock</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/sherlock_quick_start_netflix.html">`sherlock`: Causal Machine Learning for Segment Discovery</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>
<code>sherlock</code>: Causal Machine Learning for Segment Discovery</h1>
                        <h4 class="author">
<a href="https://nimahejazi.org">Nima Hejazi</a> and <a href="https://www.linkedin.com/in/wenjing-zheng">Wenjing Zheng</a>
</h4>
            
      
      
      <div class="hidden name"><code>sherlock_quick_start_netflix.Rmd</code></div>

    </div>

    
    
<div id="overview-of-sherlock" class="section level1">
<h1 class="hasAnchor">
<a href="#overview-of-sherlock" class="anchor"></a>Overview of <code>sherlock</code>
</h1>
<div id="what-is-it-for" class="section level2">
<h2 class="hasAnchor">
<a href="#what-is-it-for" class="anchor"></a>What is it for?</h2>
<p><code>sherlock</code> allows us to use data from A/B tests or observational and quasi experiments, to discover which subgroups or segments of users would benefit from (or be harmed by) a given treatment of interest. The criterion for benefit or harm could be either absolute or subject to some cost constraints. <!--
Sometimes, we may also be interested in quantifying the maximal treatment
effect heterogeneity (HTE) across the subgroups.
--></p>
<p>In these <em>Causal Segment Discovery</em> problems, we are given a set of <strong>segment dimensions/covariates</strong> that are not affected by the treatment (e.g. {country, device}). These are often a subset of the baseline covariates that are used to adjust for treatment effect confounding (in the case of non-AB data) and/or to reduce estimation variance. A <strong>segment or subgroup</strong> is a particular realization of the segment dimensions (e.g. {country=US, device=iphone12}). Our task is to learn the treatment effect heterogeneity across the segments, and which segments would satisfy a given treatment benefit criterion. The causality aspect lies in that the criterion is a function of the causal treatment effects on the segments, such as the <strong>Conditional Average Treatment Effect (CATE)</strong> on a segment. This task would result in a <strong>segmentation (or partition)</strong> of the population, into segments that should receive treatment vs those that should not. <!-- Or, in the case of quantifying a maximal HTE, it would partition the
population into two sets of segments, across which the HTE is  maximized. --></p>
<p><code>sherlock</code> implements a modular, doubly robust machine learning framework for Causal Segment Discovery (first proposed by <span class="citation">Vanderweele et al. (2019)</span>, <span class="citation">van der Laan and Luedtke (2015)</span>, <span class="citation">Luedtke and van der Laan (2016b)</span> and <span class="citation">Luedtke and van der Laan (2016a)</span>). This package has the following features:</p>
<ul>
<li>It allows the user to use any machine-learning or parametric methods to get robust and efficient estimates (and the associated standard errors) of the CATE as a function of the segments. This paves the way for applications where we have high cardinality in the segment dimensions, and/or where we have a large number of covariates to control for treatment effect confounding in non-AB data.</li>
<li>It allows the user to input an optimality criterion, which will be used to decide which segments should receive treatment. The criterion could be an absolute threshold of the CATE on a segment, or be based on capping treatment cost while maximizing treatment effect. <!-- It also allows a user to learn a maximal HTE across the segments, based
on a two-set partition of segments that would maximize the HTE between the
two sets. -->
</li>
<li>For a learned segmentation of the population, <code>sherlock</code> also provides double robust effect measures to assess how well this segmentation achieves the intended criterion.</li>
</ul>
</div>
<div id="installing-the-package" class="section level2">
<h2 class="hasAnchor">
<a href="#installing-the-package" class="anchor"></a>Installing the package</h2>
<p>Before installing <code>sherlock</code>, please make sure that you have the latest version of <a href="https://github.com/tlverse/sl3"><code>sl3</code></a>, which is the workhorse of our model estimations. You can do so via</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html">install_github</a></span><span class="op">(</span><span class="st">"tlverse/sl3@devel"</span>,  dependencies <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<p><code>sl3</code> implements an ensemble machine learning framework called Super Learner. At the current version, <code>sl3</code> has ~40 of the most popular machine learning methods to choose from as base learners.</p>
<p>When <code>sherlock</code> package is available on CRAN, it can be installed via:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"sherlock"</span><span class="op">)</span></code></pre></div>
<p>Alternatively, it can be installed from the public <code>sherlock</code> repo on Netflix Github:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html">install_github</a></span><span class="op">(</span><span class="st">"Netflix/sherlock"</span><span class="op">)</span></code></pre></div>
<p>Another option is to download the package from GitHub and install the package tarball locally.</p>
<p>Once installed, <code>sherlock</code> and <code>sl3</code> can be loaded via</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/sl3">sl3</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">sherlock</span><span class="op">)</span></code></pre></div>
</div>
</div>
<div id="how-to-use-sherlock" class="section level1">
<h1 class="hasAnchor">
<a href="#how-to-use-sherlock" class="anchor"></a>How to use <code>sherlock</code>
</h1>
<p>Overall, there are 3 main modules in this Causal Segment Discovery Framework:</p>
<ol style="list-style-type: decimal">
<li>Estimate CATE and its standard error, for each segment. This provides a summary of the Heterogeneous Treatment Effects (HTE) across the segments. (<code>sherlock_calculate</code> function)</li>
<li>Decide which segments should receive treatment (and which should not), based on a segment discovery criterion. (<code>watson_segment</code> function)</li>
<li>Evaluate the effectiveness of this segmentation. (<code>mycroft_assess</code> function)</li>
</ol>
<p>For the classes of problems addressed in this framework, step 1 would be the same regardless of the segmentation criterion, since it learns the effect of the treatment on each segment. Steps 2 and 3 depend on the segmentation criterion and what would be an appropriate effectiveness evaluation. Hence, step 1 only needs to be run once. After that, we can run different segmentation criteria and corresponding effectiveness evaluations.</p>
<div id="step-0--data-structure" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#step-0--data-structure" class="anchor"></a>Step 0. Data structure</h2>
<p>We illustrate the steps with a synthetic data example. Suppose we want to learn whether a new UI treatment would have a differential impact on segments of our users, where segments are defined by the number of devices they have and their tenure.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">data_example</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">data_example</span><span class="op">)</span>
<span class="co">#&gt;    num_devices is_p2plus is_newmarket baseline_ltv baseline_viewing treatment</span>
<span class="co">#&gt; 1:           2         1            0    0.3500025       0.01014789         0</span>
<span class="co">#&gt; 2:           4         0            0    0.8144417       1.56213812         1</span>
<span class="co">#&gt; 3:           3         0            1    0.0000000       0.41284605         0</span>
<span class="co">#&gt; 4:           5         1            0    0.0000000       0.00000000         0</span>
<span class="co">#&gt; 5:           5         1            0    0.0000000       0.71454993         1</span>
<span class="co">#&gt; 6:           1         1            0    0.0000000       0.58507617         0</span>
<span class="co">#&gt;    outcome_viewing</span>
<span class="co">#&gt; 1:       0.3500025</span>
<span class="co">#&gt; 2:       5.0144417</span>
<span class="co">#&gt; 3:       1.0000000</span>
<span class="co">#&gt; 4:       0.0000000</span>
<span class="co">#&gt; 5:      -3.0000000</span>
<span class="co">#&gt; 6:       0.0000000</span></code></pre></div>
<p>Here the column <code>treatment</code> represents the treatment of interest <span class="math inline">\(A\)</span>, the column <code>outcome_viewing</code> represents the outcome of interest <span class="math inline">\(Y\)</span>. All the other columns make up the baseline covariates <span class="math inline">\(W\)</span>, which we shall use to control for treatment effect confounding and to reduce variance. Let <span class="math inline">\(V\)</span>={<code>num_devices</code>, <code>is_p2plus</code>} be our segment dimensions of interest. Note that we always have <span class="math inline">\(V\subseteq W\)</span>. If the data has repeated measures on the independent units, we would have an additional <code>id</code> column, where rows pertaining to the same unit should have the same <code>id</code> value.</p>
<p>At this point, we make no assumptions on whether this data is from AB-tests. That assumption only comes in later when we either provide the treatment allocation rate (if AB test) or an estimation method to fit the treatment propensity (if non-AB).</p>
</div>
<div id="step-1--estimate-the-conditional-average-treatment-effect-on-each-segment" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#step-1--estimate-the-conditional-average-treatment-effect-on-each-segment" class="anchor"></a>Step 1. Estimate the Conditional Average Treatment Effect on each segment</h2>
<p>For a segment <span class="math inline">\(V=v\)</span>, <span class="math inline">\(CATE(v) = E[E(Y|A=1,W)-E(Y|A=0,W)|V=v)]\)</span> is the <strong>Conditional Average Treatment Effect (CATE)</strong> on this segment. It captures the average difference in outcome, if users in this segment had received treatment <span class="math inline">\(A=1\)</span> vs control <span class="math inline">\(A=0\)</span>. We want to estimate <span class="math inline">\(CATE(v)\)</span> across all the segments <span class="math inline">\(v\)</span>.</p>
<p>This task can be modularized in terms of estimating the nuisance parameters:</p>
<ul>
<li>outcome regression E(Y|A,W)</li>
<li>the propensity score (if non-AB) p(A|W)</li>
<li>the regression CATE(v) = E[ E(Y|A=1,W)-E(Y|A=0,W)|V=v]</li>
</ul>
<p>Each nuisance parameter can be estimated using ML methods specified by the user, or selected via a cross-validation procedure. These are implemented via <code>sl3</code>.</p>
<div id="step-1-1-specifying-the-machine-learners" class="section level3 unnumbered">
<h3 class="hasAnchor">
<a href="#step-1-1-specifying-the-machine-learners" class="anchor"></a>Step 1.1 Specifying the machine learners</h3>
<p>As mentioned above, we use <a href="https://github.com/tlverse/sl3"><code>sl3</code></a> to implement the machine learning methods to estimate the propensity score, the outcome model and the CATE. When given one base learner (one machine learning method spec), <code>sl3</code> will fit this learner as if using the algo’s package directly. But when given multiple base learners (different methods and different tuning specs), <code>sl3</code> will fit the best linear combination of these, wherein “best” is chosen by a cross-validated risk. Currently, there are ~30 machine learners methods available for binary dependent variables, and ~40 available for continuous dependent variables.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">##### list all the supported ML algos in sl3</span>
<span class="fu"><a href="https://tlverse.org/sl3/reference/list_learners.html">sl3_list_learners</a></span><span class="op">(</span><span class="st">"binomial"</span><span class="op">)</span> <span class="co">## ML algos for binary dependent variables</span>
<span class="co">#&gt;  [1] "Lrnr_bartMachine"               "Lrnr_bayesglm"                 </span>
<span class="co">#&gt;  [3] "Lrnr_bound"                     "Lrnr_caret"                    </span>
<span class="co">#&gt;  [5] "Lrnr_cv_selector"               "Lrnr_dbarts"                   </span>
<span class="co">#&gt;  [7] "Lrnr_earth"                     "Lrnr_gam"                      </span>
<span class="co">#&gt;  [9] "Lrnr_gbm"                       "Lrnr_glm"                      </span>
<span class="co">#&gt; [11] "Lrnr_glm_fast"                  "Lrnr_glmnet"                   </span>
<span class="co">#&gt; [13] "Lrnr_grf"                       "Lrnr_gru_keras"                </span>
<span class="co">#&gt; [15] "Lrnr_h2o_glm"                   "Lrnr_h2o_grid"                 </span>
<span class="co">#&gt; [17] "Lrnr_hal9001"                   "Lrnr_lightgbm"                 </span>
<span class="co">#&gt; [19] "Lrnr_lstm_keras"                "Lrnr_mean"                     </span>
<span class="co">#&gt; [21] "Lrnr_nnet"                      "Lrnr_optim"                    </span>
<span class="co">#&gt; [23] "Lrnr_pkg_SuperLearner"          "Lrnr_pkg_SuperLearner_method"  </span>
<span class="co">#&gt; [25] "Lrnr_pkg_SuperLearner_screener" "Lrnr_polspline"                </span>
<span class="co">#&gt; [27] "Lrnr_randomForest"              "Lrnr_ranger"                   </span>
<span class="co">#&gt; [29] "Lrnr_rpart"                     "Lrnr_screener_correlation"     </span>
<span class="co">#&gt; [31] "Lrnr_solnp"                     "Lrnr_stratified"               </span>
<span class="co">#&gt; [33] "Lrnr_svm"                       "Lrnr_xgboost"</span>
<span class="fu"><a href="https://tlverse.org/sl3/reference/list_learners.html">sl3_list_learners</a></span><span class="op">(</span><span class="st">"continuous"</span><span class="op">)</span> <span class="co">## ML algos for continuous dependent variables</span>
<span class="co">#&gt;  [1] "Lrnr_arima"                     "Lrnr_bartMachine"              </span>
<span class="co">#&gt;  [3] "Lrnr_bayesglm"                  "Lrnr_bilstm"                   </span>
<span class="co">#&gt;  [5] "Lrnr_bound"                     "Lrnr_caret"                    </span>
<span class="co">#&gt;  [7] "Lrnr_cv_selector"               "Lrnr_dbarts"                   </span>
<span class="co">#&gt;  [9] "Lrnr_earth"                     "Lrnr_expSmooth"                </span>
<span class="co">#&gt; [11] "Lrnr_gam"                       "Lrnr_gbm"                      </span>
<span class="co">#&gt; [13] "Lrnr_glm"                       "Lrnr_glm_fast"                 </span>
<span class="co">#&gt; [15] "Lrnr_glmnet"                    "Lrnr_grf"                      </span>
<span class="co">#&gt; [17] "Lrnr_gru_keras"                 "Lrnr_gts"                      </span>
<span class="co">#&gt; [19] "Lrnr_h2o_glm"                   "Lrnr_h2o_grid"                 </span>
<span class="co">#&gt; [21] "Lrnr_hal9001"                   "Lrnr_HarmonicReg"              </span>
<span class="co">#&gt; [23] "Lrnr_hts"                       "Lrnr_lightgbm"                 </span>
<span class="co">#&gt; [25] "Lrnr_lstm_keras"                "Lrnr_mean"                     </span>
<span class="co">#&gt; [27] "Lrnr_multiple_ts"               "Lrnr_nnet"                     </span>
<span class="co">#&gt; [29] "Lrnr_nnls"                      "Lrnr_optim"                    </span>
<span class="co">#&gt; [31] "Lrnr_pkg_SuperLearner"          "Lrnr_pkg_SuperLearner_method"  </span>
<span class="co">#&gt; [33] "Lrnr_pkg_SuperLearner_screener" "Lrnr_polspline"                </span>
<span class="co">#&gt; [35] "Lrnr_randomForest"              "Lrnr_ranger"                   </span>
<span class="co">#&gt; [37] "Lrnr_rpart"                     "Lrnr_rugarch"                  </span>
<span class="co">#&gt; [39] "Lrnr_screener_correlation"      "Lrnr_solnp"                    </span>
<span class="co">#&gt; [41] "Lrnr_stratified"                "Lrnr_svm"                      </span>
<span class="co">#&gt; [43] "Lrnr_tsDyn"                     "Lrnr_xgboost"</span></code></pre></div>
<p>Documentation for the tuning parameters of each learner can be found in <a href="https://tlverse.org/sl3/reference/index.html#section-sl-learners"><code>sl3</code> Learners Reference</a>. Use <code>?Lrnr...</code> to see which model defaults are used. For now, we show a few examples of base learner specifications:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># a random forest base learner implemented by `ranger` package</span>
<span class="va">lrn_ranger100</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_ranger.html">Lrnr_ranger</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>num.trees <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>

<span class="co"># xgboost base learners</span>
<span class="va">xgb_fast</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_xgboost.html">Lrnr_xgboost</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span> <span class="co"># defaults from `xgboost` package (nrounds=20)</span>
<span class="va">xgb_50</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_xgboost.html">Lrnr_xgboost</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>nrounds <span class="op">=</span> <span class="fl">50</span>, max_depth <span class="op">=</span> <span class="fl">6</span>, eta <span class="op">=</span> <span class="fl">0.001</span><span class="op">)</span>

<span class="co"># For learners that require a formula specification, the instantiated learner</span>
<span class="co"># uses main terms derived from the input data, additional interaction</span>
<span class="co"># terms need to be specified separately when calling sherlock:</span>
<span class="va">lrn_glm</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm.html">Lrnr_glm</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">lrn_lasso</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span> <span class="co"># default is alpha=1, which is the LASSO</span>
<span class="va">lrn_ridge_interaction</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">lrn_enet.5_interaction</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>

<span class="co">### example: additional interaction terms of treatment with segment dimensions</span>
<span class="va">or_interactions</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"treatment"</span>, <span class="st">"num_devices"</span><span class="op">)</span>,
                        <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"treatment"</span>, <span class="st">"is_p2plus"</span><span class="op">)</span>,
                        <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"treatment"</span>, <span class="st">"num_devices"</span>, <span class="st">"is_p2plus"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Next, we specify which learners we want to use to estimate the outcome model, propensity score, and the final CATE parameter. At this point, we do not need to specify the dependent and independent variables, as that will be handled inside <code>sherlock</code> methods. For example, we can choose:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">##### for each nuisance parameter, we illustrate one way of using sl3</span>

<span class="co"># to estimate the propensity score p(A|W):</span>
<span class="co"># for example, we use only one learner. Here sl3 will just directly call</span>
<span class="co"># xgboost to fit according to tuning params</span>
<span class="va">ps_learner_spec</span> <span class="op">&lt;-</span> <span class="va">xgb_50</span>
<span class="co"># if data is from a AB test, where treatment is allocated at a fixed rate p,</span>
<span class="co"># say, p = 0.5, then we can also specify:</span>
<span class="co"># ps_learner &lt;- 0.5</span>

<span class="co"># to estimate the outcome regression E(Y|A,W):</span>
<span class="co"># for example, we use a linear ensemble with 3 base learners:</span>
<span class="co">#  {ranger, xgboost, lasso with the specified interactions}.</span>
<span class="va">or_learner_spec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">lrn_ranger100</span>, <span class="va">xgb_fast</span>,
                        <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">or_interactions</span>, <span class="va">lrn_lasso</span><span class="op">)</span><span class="op">)</span>
<span class="co"># if we are not using models that specify the interaction terms, then we can</span>
<span class="co"># instantiate the ensemble models directly. For example:</span>
<span class="co"># or_learner_spec &lt;- Lrnr_sl$new(learners = list(lrn_ranger100,xgb_fast))</span>

<span class="co"># to estimate CATE(V) = E( E(Y|1,W)-E(Y|0,W) | V):</span>
<span class="co"># for example, we use cross-validation to select best among ranger and xgboost</span>
<span class="va">cate_learner_spec</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  learners <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">lrn_ranger100</span>, <span class="va">xgb_fast</span><span class="op">)</span>,
  metalearner <span class="op">=</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_cv_selector.html">Lrnr_cv_selector</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div id="step-1-2-using-the-learners-to-obtain-double-robust-estimation-of-cate" class="section level4 unnumbered">
<h4 class="hasAnchor">
<a href="#step-1-2-using-the-learners-to-obtain-double-robust-estimation-of-cate" class="anchor"></a>Step 1.2 Using the learners to obtain double robust estimation of CATE</h4>
<p>Now, we can call the function <code>sherlock_calculate</code> with these ml methods to calculate the CATE on the segments. The argument <code>baseline</code> specifies all the covariates <span class="math inline">\(W\)</span> we want to use to adjust for confounding and/or to increase estimation efficiency. The <code>segment_by</code> argument lists the segment dimensions <span class="math inline">\(V\)</span> along which we want to segment users. It must be a subset of <code>baseline</code>. The arguments <code>ps_learner</code>, <code>or_learner</code> and <code>cate_learner</code> take the specified machine learning methods or parametric models (examples shown above), for the propensity score, outcome regression and CATE estimates, respectively. If instead of using an ensemble learner, we wish to only select the best among the list of candidate learners for each nuisance parameter, we can specify the argument <code>use_cv_selector=TRUE</code> (default is <code>FALSE</code>) in <code>sherlok_calculate</code>. The dependent and independent variables used in each learner will be based on the variable groups we specified and the nuisance parameter being estimated.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sherlock_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sherlock_calculate.html">sherlock_calculate</a></span><span class="op">(</span>
  data_from_case <span class="op">=</span> <span class="va">data_example</span>,
  baseline <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"num_devices"</span>, <span class="st">"is_p2plus"</span>, <span class="st">"is_newmarket"</span>, <span class="st">"baseline_ltv"</span>,
               <span class="st">"baseline_viewing"</span><span class="op">)</span>,
  exposure <span class="op">=</span> <span class="st">"treatment"</span>,
  outcome <span class="op">=</span> <span class="st">"outcome_viewing"</span>,
  segment_by <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"num_devices"</span>, <span class="st">"is_p2plus"</span><span class="op">)</span>,
  cv_folds <span class="op">=</span> <span class="fl">5L</span>,
  ps_learner <span class="op">=</span> <span class="va">ps_learner_spec</span>,
  or_learner <span class="op">=</span> <span class="va">or_learner_spec</span>,
  cate_learner <span class="op">=</span> <span class="va">cate_learner_spec</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sherlock_results</span><span class="op">)</span>
<span class="co">#&gt;     num_devices is_p2plus segment_proportion    cate   lwr_ci  upr_ci std_err</span>
<span class="co">#&gt;  1:           1         0             0.0392  0.2276  0.04807  0.4071 0.09159</span>
<span class="co">#&gt;  2:           1         1             0.0862  1.9094  1.79907  2.0197 0.05629</span>
<span class="co">#&gt;  3:           2         0             0.0718 -0.6080 -0.73109 -0.4849 0.06281</span>
<span class="co">#&gt;  4:           2         1             0.1752  2.5473  2.47101  2.6235 0.03891</span>
<span class="co">#&gt;  5:           3         0             0.0764 -1.4581 -1.57710 -1.3390 0.06074</span>
<span class="co">#&gt;  6:           3         1             0.1796  3.3866  3.30491  3.4682 0.04166</span>
<span class="co">#&gt;  7:           4         0             0.0728  4.2903  4.16778  4.4128 0.06251</span>
<span class="co">#&gt;  8:           4         1             0.1814 -2.2065 -2.28349 -2.1296 0.03926</span>
<span class="co">#&gt;  9:           5         0             0.0328  5.0104  4.79779  5.2231 0.10850</span>
<span class="co">#&gt; 10:           5         1             0.0846 -2.8414 -2.96196 -2.7208 0.06152</span></code></pre></div>
<p>We can visualize the CATE estimation results from <code>sherlock_calculate</code> as follows:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">sherlock_results</span>, plot_type <span class="op">=</span> <span class="st">"cate"</span><span class="op">)</span></code></pre></div>
<p><code>sherlock_calculate</code> returns an object of class <code>sherlock</code>, which is also a <code>data.table</code> object representing the input data set, with the estimated treatment probabilities, outcome estimates and CATE estimates attached to it. The default print out (or a call <code>attr(sherlock_results,'summary')</code> ) will provide for each segment, the segment proportion in the population, its estimated CATE and associated confidence intervals and standard error. This readily provides a view of the HTE across the segments.</p>
</div>
</div>
</div>
<div id="steps-2-and-3-finding-segments-to-treat-and-evaluate-effectiveness-of-the-segmentation-" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#steps-2-and-3-finding-segments-to-treat-and-evaluate-effectiveness-of-the-segmentation-" class="anchor"></a>Steps 2 and 3: Finding Segments to Treat and Evaluate Effectiveness of the Segmentation.</h2>
<p>In step 1, we obtained a summary of the HTE by estimating the CATE across the segments. Now, we will consider a few examples of finding the optimal segments to treat based on a segment discovery criterion. We do not need to rerun <code>sherlock_calculate</code> when we want to try a new criterion, unless the data is changed (see example 3).</p>
<div id="example-1-finding-segments-that-would-benefit-from-treatment-according-to-a-fixed-benefit-threshold" class="section level3 unnumbered">
<h3 class="hasAnchor">
<a href="#example-1-finding-segments-that-would-benefit-from-treatment-according-to-a-fixed-benefit-threshold" class="anchor"></a>Example 1: Finding segments that would benefit from treatment, according to a fixed benefit threshold</h3>
<div id="step-2--finding-segments-to-treat-based-on-benefit-threshold" class="section level4 unnumbered">
<h4 class="hasAnchor">
<a href="#step-2--finding-segments-to-treat-based-on-benefit-threshold" class="anchor"></a>Step 2. Finding segments to treat based on benefit threshold</h4>
<p>Suppose we want to find all the segments that would benefit from the treatment, where “benefit” is determined by having <span class="math inline">\(CATE(v) &gt;\)</span> <code>threshold</code>, for some user-specified threshold. We can do so by calling the <code>watson_segment</code> function, with the segmentation function <code><a href="../reference/cost_funs.html">cost_threshold()</a></code> and the desired benefit threshold. In this example, <code>threshold=0</code> means that we consider a segment with <span class="math inline">\(CATE(v)&gt;0\)</span> to be benefiting from treatment, and hence “should be treated”. The argument <code>type=inferential</code> specifies that the determination of <span class="math inline">\(CATE(v) &gt;\)</span> <code>threshold</code> is based on an upper-tail hypothesis test with the standard errors of the CATE estimates and multiple comparison adjustments. By contrast, <code>type=analytical</code> means that the determination is only based on the point estimate <span class="math inline">\(CATE(v)\)</span>, without hypothesis testing. When the sizes of some segments are very small, we suggest either using <code>type=analytical</code> as the hypothesis testing will be inaccurate or refactoring the segment dimensions to allow for bigger segments.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sherlock_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/watson_segment.html">watson_segment</a></span><span class="op">(</span>
  <span class="va">sherlock_results</span>,
  segment_fun <span class="op">=</span> <span class="va">cost_threshold</span>,
  threshold <span class="op">=</span> <span class="fl">0</span>,
  type <span class="op">=</span> <span class="st">"inferential"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sherlock_results</span><span class="op">)</span>
<span class="co">#&gt;     num_devices is_p2plus segment_proportion    cate   lwr_ci  upr_ci std_err</span>
<span class="co">#&gt;  1:           1         0             0.0392  0.2276  0.04807  0.4071 0.09159</span>
<span class="co">#&gt;  2:           1         1             0.0862  1.9094  1.79907  2.0197 0.05629</span>
<span class="co">#&gt;  3:           2         0             0.0718 -0.6080 -0.73109 -0.4849 0.06281</span>
<span class="co">#&gt;  4:           2         1             0.1752  2.5473  2.47101  2.6235 0.03891</span>
<span class="co">#&gt;  5:           3         0             0.0764 -1.4581 -1.57710 -1.3390 0.06074</span>
<span class="co">#&gt;  6:           3         1             0.1796  3.3866  3.30491  3.4682 0.04166</span>
<span class="co">#&gt;  7:           4         0             0.0728  4.2903  4.16778  4.4128 0.06251</span>
<span class="co">#&gt;  8:           4         1             0.1814 -2.2065 -2.28349 -2.1296 0.03926</span>
<span class="co">#&gt;  9:           5         0             0.0328  5.0104  4.79779  5.2231 0.10850</span>
<span class="co">#&gt; 10:           5         1             0.0846 -2.8414 -2.96196 -2.7208 0.06152</span>
<span class="co">#&gt;     threshold test_stat       pval   pval_adj rule</span>
<span class="co">#&gt;  1:         0     2.485  6.481e-03  1.080e-02    1</span>
<span class="co">#&gt;  2:         0    33.920 1.681e-252 3.363e-252    1</span>
<span class="co">#&gt;  3:         0    -9.680  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  4:         0    65.465  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt;  5:         0   -24.005  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  6:         0    81.299  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt;  7:         0    68.635  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt;  8:         0   -56.203  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  9:         0    46.179  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt; 10:         0   -46.187  1.000e+00  1.000e+00    0</span></code></pre></div>
<p>We can visualize the treatment decisions from <code>watson_segment</code> as follows:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">sherlock_results</span>, plot_type <span class="op">=</span> <span class="st">"treatment_decisions"</span><span class="op">)</span></code></pre></div>
<p>The <code>watson_segment</code> function attaches to each individual the recommended treatment rule of their segment: <code>rule=1</code> means “should receive treatment”, <code>rule=0</code> means “should not receive treatment”. The default print out (or a call <code>attr(sherlock_results, "summary")</code> ) provides a summary of the segment discovery. For example: segment <code>{num_devices=1, is_p2plus=1}</code> should receive treatment (<code>rule=1</code>) because we can conclude that <span class="math inline">\(CATE(v) &gt; 0\)</span> based on the p-values (adjusted for multiple comparisons). Similarly, <code>{num_devices=2, is_p2plus=0}</code> should not receive treatment.</p>
</div>
<div id="step-3--assessing-the-effectiveness-of-the-segmentation-" class="section level4 unnumbered">
<h4 class="hasAnchor">
<a href="#step-3--assessing-the-effectiveness-of-the-segmentation-" class="anchor"></a>Step 3. Assessing the effectiveness of the segmentation.</h4>
<p>Step 2 used the CATE estimates to determine which segments should be treated. But how effective is such segmentation in maximizing outcomes, compared to global one-size-fits-all strategies? Or what are the treatment effects on all segments that should receive treatment vs those that should not? We can assess these using the <code>mycroft_assess</code> function, which provides double-robust estimation of the Optimal Treatment Effects (<code>param_type = "ote"</code>) or Heterogeneous Average Treatment Effects ((<code>param_type = "hte"</code>).</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Optimal Treatment Effects (OTE) from rule-based treatment"</span>
<span class="va">ote_example</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mycroft_assess.html">mycroft_assess</a></span><span class="op">(</span>
  <span class="va">sherlock_results</span>,
  param_type <span class="op">=</span> <span class="st">"ote"</span>
<span class="op">)</span>

<span class="co"># friendly print out</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">ote_example</span><span class="op">)</span>
<span class="co">#&gt; Counterfactual Mean Outcome If All Get Treatment</span>
<span class="co">#&gt;   Parameter Estimate:  2.183 </span>
<span class="co">#&gt;   95% Conf Interval: (2.103, 2.264) </span>
<span class="co">#&gt;   Standard Error:  0.04094 </span>
<span class="co">#&gt; Counterfactual Mean Outcome If All Get Control</span>
<span class="co">#&gt;   Parameter Estimate:  1.271 </span>
<span class="co">#&gt;   95% Conf Interval: (1.241, 1.302) </span>
<span class="co">#&gt;   Standard Error:  0.01546 </span>
<span class="co">#&gt; Counterfactual Mean Outcome If Treat Based on Segment Rule</span>
<span class="co">#&gt;   Parameter Estimate:  2.999 </span>
<span class="co">#&gt;   95% Conf Interval: (2.942, 3.055) </span>
<span class="co">#&gt;   Standard Error:  0.02881 </span>
<span class="co">#&gt; Optimal Treatment Effect: Treat based on Segment Rule vs. All Get Treatment</span>
<span class="co">#&gt;   Parameter Estimate:  0.8152 </span>
<span class="co">#&gt;   95% Conf Interval: (0.7783, 0.852) </span>
<span class="co">#&gt;   Standard Error:  0.0188 </span>
<span class="co">#&gt; Optimal Treatment Effect: Treat based on Segment Rule vs All Get Control</span>
<span class="co">#&gt;   Parameter Estimate:  1.727 </span>
<span class="co">#&gt;   95% Conf Interval: (1.674, 1.781) </span>
<span class="co">#&gt;   Standard Error:  0.02729</span>

<span class="co"># tabular print out</span>
<span class="va">ote_example</span> <span class="op">%&gt;%</span>
  <span class="fu">as.data.table</span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt;                      param  estimate    lwr_ci    upr_ci    std_err</span>
<span class="co">#&gt; 1:             tsm_trt_all 2.1834466 2.1032112 2.2636819 0.04093715</span>
<span class="co">#&gt; 2:             tsm_ctl_all 1.2714350 1.2411414 1.3017286 0.01545621</span>
<span class="co">#&gt; 3:            tsm_trt_rule 2.9986003 2.9421272 3.0550733 0.02881330</span>
<span class="co">#&gt; 4: ate_trt_rule_vs_trt_all 0.8151537 0.7783017 0.8520057 0.01880237</span>
<span class="co">#&gt; 5: ate_trt_rule_vs_ctl_all 1.7271653 1.6736818 1.7806488 0.02728800</span></code></pre></div>
<p>The first 3 “Counterfactual Mean Outcome” parameters are the counterfactual mean outcome under the global ‘all get treatment’ strategy, ‘all get control’ strategy, and the targeted strategy of ‘treat based on segment rule’, where the segment rule was learned in step 2 using <code>watson_segment</code>. The last two “optimal treatment effect” parameters are the differences in outcome of the rule-based strategy vs the global ‘treat all’ and ‘control all’ strategies, respectively. These allow us to evaluate the gain in implementing the segment-rule based strategy, compared to a more convenient global strategy.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## "Heterogeneous Treatment Effect (HTE) Based on Segmentation"</span>
<span class="va">hte_example</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mycroft_assess.html">mycroft_assess</a></span><span class="op">(</span>
  <span class="va">sherlock_results</span>,
  param_type <span class="op">=</span> <span class="st">"hte"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">hte_example</span><span class="op">)</span>
<span class="co">#&gt; Average Treatment Effect (All Get Treatment vs All Get Control) on Population:</span>
<span class="co">#&gt;   Parameter Estimate:  0.912 </span>
<span class="co">#&gt;   95% Conf Interval: (0.8321, 0.9919) </span>
<span class="co">#&gt;   Standard Error:  0.04076 </span>
<span class="co">#&gt; Average Treatment Effect on Segments with Recommended Treatment (Rule = 1)</span>
<span class="co">#&gt;   Parameter Estimate:  2.948 </span>
<span class="co">#&gt;   95% Conf Interval: (2.888, 3.008) </span>
<span class="co">#&gt;   Standard Error:  0.03067 </span>
<span class="co">#&gt; Average Treatment Effect on Segments with Recommended Controle (Rule = 0)</span>
<span class="co">#&gt;   Parameter Estimate:  -1.968 </span>
<span class="co">#&gt;   95% Conf Interval: (-2.029, -1.907) </span>
<span class="co">#&gt;   Standard Error:  0.03107 </span>
<span class="co">#&gt; Difference in Average Treatment Effect: Segments with Recommended Treatment vs Segments with Recommended Control </span>
<span class="co">#&gt;   Parameter Estimate:  4.916 </span>
<span class="co">#&gt;   95% Conf Interval: (4.831, 5.002) </span>
<span class="co">#&gt;   Standard Error:  0.04365</span></code></pre></div>
<p>The first 3 “Average Treatment Effect” parameters evaluate the average treatment effect (treat-all vs control-all), on the whole population, on the segments where treatment is recommended (<code>rule=1</code>), and on the segments where treatment is not recommended (<code>rule=0</code>). “Difference in ATE” parameter is the difference in Average Treatment Effect between the two segment groups (ATE on <code>rule==1</code> group vs ATE on <code>rule=0</code> group).</p>
</div>
</div>
<div id="example-2-finding-segments-that-should-receive-treatment-if-we-can-only-treat-a-fixed-percent-of-the-population" class="section level3 unnumbered">
<h3 class="hasAnchor">
<a href="#example-2-finding-segments-that-should-receive-treatment-if-we-can-only-treat-a-fixed-percent-of-the-population" class="anchor"></a>Example 2: Finding segments that should receive treatment, if we can only treat a fixed percent of the population</h3>
<p>Consider the use case where treating each unit incurs a fixed cost, and as a result we are only able to treat at most <span class="math inline">\((100\times q)\%\)</span> of the population, for a given rate <span class="math inline">\(q\in (0,1)\)</span>. Our goal is to find segments that should receive treatment, but subject to this population-level constraint. Implicit in this use case is that the treatment will be beneficial for at least <span class="math inline">\((100\times q)\%\)</span> of the population. Otherwise the constraint doesn’t apply and we are back in the use case of example 1.</p>
<p>This use case can be formulated in terms of the <em>knapsack problem</em>, where the goal is find the set of segments <span class="math inline">\(T\subseteq \{v: CATE(v) &gt; 0\}\)</span> that maximizes <span class="math inline">\(\sum_{v\in T} CATE(v)\)</span>, subject to the constraint <span class="math inline">\(\sum_{v\in T} p(v) \leq q\)</span>. Our package uses the <code>knapsack</code> implementation in <a href="https://CRAN.R-project.org/package=adagio"><code>adagio</code></a>.</p>
<p>We already obtained CATE for each segment in step 1. So now, in step 2, we use the segmentation function <code><a href="../reference/cost_funs.html">cost_knapsack()</a></code> instead. This function uses the argument <code>budget</code> to specify the treatment budget constraint <span class="math inline">\(q\)</span>. Suppose we have a budget to treat only 20% of the population: <code>budget=0.2</code>. The argument <code>type=inferential</code> specifies that the determination of <span class="math inline">\(CATE(v) &gt; 0\)</span> should be based on hypothesis testing with multiple comparison adjustments. If <code>type=analytic</code>, then only the determination is only based on the point estimates. Recall that we had run <code>watson_segment</code> once already using <code>segment_fun=cost_threshold</code> in example 1. Now, this new segmentation will overwrite the previous one.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sherlock_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/watson_segment.html">watson_segment</a></span><span class="op">(</span>
  <span class="va">sherlock_results</span>,
  segment_fun <span class="op">=</span> <span class="va">cost_knapsack</span>,
  budget <span class="op">=</span> <span class="fl">0.2</span>,
  type <span class="op">=</span> <span class="st">"inferential"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sherlock_results</span><span class="op">)</span>
<span class="co">#&gt;     num_devices is_p2plus segment_proportion    cate   lwr_ci  upr_ci std_err</span>
<span class="co">#&gt;  1:           1         0             0.0392  0.2276  0.04807  0.4071 0.09159</span>
<span class="co">#&gt;  2:           1         1             0.0862  1.9094  1.79907  2.0197 0.05629</span>
<span class="co">#&gt;  3:           2         0             0.0718 -0.6080 -0.73109 -0.4849 0.06281</span>
<span class="co">#&gt;  4:           2         1             0.1752  2.5473  2.47101  2.6235 0.03891</span>
<span class="co">#&gt;  5:           3         0             0.0764 -1.4581 -1.57710 -1.3390 0.06074</span>
<span class="co">#&gt;  6:           3         1             0.1796  3.3866  3.30491  3.4682 0.04166</span>
<span class="co">#&gt;  7:           4         0             0.0728  4.2903  4.16778  4.4128 0.06251</span>
<span class="co">#&gt;  8:           4         1             0.1814 -2.2065 -2.28349 -2.1296 0.03926</span>
<span class="co">#&gt;  9:           5         0             0.0328  5.0104  4.79779  5.2231 0.10850</span>
<span class="co">#&gt; 10:           5         1             0.0846 -2.8414 -2.96196 -2.7208 0.06152</span>
<span class="co">#&gt;     threshold test_stat       pval   pval_adj rule</span>
<span class="co">#&gt;  1:         0     2.485  6.481e-03  1.080e-02    0</span>
<span class="co">#&gt;  2:         0    33.920 1.681e-252 3.363e-252    1</span>
<span class="co">#&gt;  3:         0    -9.680  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  4:         0    65.465  0.000e+00  0.000e+00    0</span>
<span class="co">#&gt;  5:         0   -24.005  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  6:         0    81.299  0.000e+00  0.000e+00    0</span>
<span class="co">#&gt;  7:         0    68.635  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt;  8:         0   -56.203  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  9:         0    46.179  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt; 10:         0   -46.187  1.000e+00  1.000e+00    0</span></code></pre></div>
<p>As before, we can visualize the treatment decisions from <code>watson_segment</code> as follows:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">sherlock_results</span>, plot_type <span class="op">=</span> <span class="st">"treatment_decisions"</span><span class="op">)</span></code></pre></div>
<p>Similar to the previous example, <code>rule=1</code> means that the segment should receive treatment, <code>rule=0</code> otherwise. Compared to the optimality criterion in example 1 (<span class="math inline">\(CATE(v)&gt;0\)</span>), we have fewer “treat” segments now. The column <code>segment_proportion</code> records <span class="math inline">\(p(v)\)</span>, the segment’s share of the population. We can check that the chosen “treat” segments make up 19.18% of the population, thus satisfying the constraint of <span class="math inline">\(\sum_{v\in T} p(v) \leq 0.2\)</span>:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">sherlock_results</span>, <span class="st">"summary"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">rule</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span>
<span class="co">#&gt;    num_devices is_p2plus segment_proportion     cate   lwr_ci   upr_ci</span>
<span class="co">#&gt; 1:           1         1             0.0862 1.909396 1.799068 2.019724</span>
<span class="co">#&gt; 2:           4         0             0.0728 4.290297 4.167781 4.412812</span>
<span class="co">#&gt; 3:           5         0             0.0328 5.010449 4.797790 5.223107</span>
<span class="co">#&gt;       std_err threshold test_stat          pval      pval_adj rule</span>
<span class="co">#&gt; 1: 0.05629092         0  33.92014 1.681335e-252 3.362669e-252    1</span>
<span class="co">#&gt; 2: 0.06250893         0  68.63494  0.000000e+00  0.000000e+00    1</span>
<span class="co">#&gt; 3: 0.10850133         0  46.17869  0.000000e+00  0.000000e+00    1</span>
<span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">sherlock_results</span>, <span class="st">"summary"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">rule</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">pull</span><span class="op">(</span><span class="va">segment_proportion</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.1918</span></code></pre></div>
<p>Since the constraint has prevented us from choosing all the segments that would benefit from treatment, we should expect that the resulting segment-rule based strategy will perform less optimally than the one we learned in example 1. Indeed:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/mycroft_assess.html">mycroft_assess</a></span><span class="op">(</span>
  <span class="va">sherlock_results</span>,
  param_type <span class="op">=</span> <span class="st">"ote"</span>
<span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">print</span>
<span class="co">#&gt; Counterfactual Mean Outcome If All Get Treatment</span>
<span class="co">#&gt;   Parameter Estimate:  2.183 </span>
<span class="co">#&gt;   95% Conf Interval: (2.103, 2.264) </span>
<span class="co">#&gt;   Standard Error:  0.04094 </span>
<span class="co">#&gt; Counterfactual Mean Outcome If All Get Control</span>
<span class="co">#&gt;   Parameter Estimate:  1.271 </span>
<span class="co">#&gt;   95% Conf Interval: (1.241, 1.302) </span>
<span class="co">#&gt;   Standard Error:  0.01546 </span>
<span class="co">#&gt; Counterfactual Mean Outcome If Treat Based on Segment Rule</span>
<span class="co">#&gt;   Parameter Estimate:  1.923 </span>
<span class="co">#&gt;   95% Conf Interval: (1.872, 1.975) </span>
<span class="co">#&gt;   Standard Error:  0.02625 </span>
<span class="co">#&gt; Optimal Treatment Effect: Treat based on Segment Rule vs. All Get Treatment</span>
<span class="co">#&gt;   Parameter Estimate:  -0.2602 </span>
<span class="co">#&gt;   95% Conf Interval: (-0.3292, -0.1911) </span>
<span class="co">#&gt;   Standard Error:  0.03524 </span>
<span class="co">#&gt; Optimal Treatment Effect: Treat based on Segment Rule vs All Get Control</span>
<span class="co">#&gt;   Parameter Estimate:  0.6519 </span>
<span class="co">#&gt;   95% Conf Interval: (0.6086, 0.6951) </span>
<span class="co">#&gt;   Standard Error:  0.02208</span></code></pre></div>
<p>The “Counterfactual Mean Outcome If Treat Based on Segment Rule” in this example is less than the corresponding one in example 1.</p>
</div>
<div id="example-3-finding-segments-that-should-receive-treatment-if-we-need-to-cap-the-average-treatment-cost-per-unit" class="section level3 unnumbered">
<h3 class="hasAnchor">
<a href="#example-3-finding-segments-that-should-receive-treatment-if-we-need-to-cap-the-average-treatment-cost-per-unit" class="anchor"></a>Example 3: Finding segments that should receive treatment, if we need to cap the average treatment cost per unit</h3>
<p>Now, we consider a more general use case where treating each unit incurs a cost that depends on its segment and other unit-level factors. In finding which segments should receive treatment and which should receive control, we want to ensure that the resulting average cost per unit across the population is capped. Let <span class="math inline">\(Cost(v)\)</span> be the average cost of treating a unit in segment <span class="math inline">\(V=v\)</span>. Then, <span class="math inline">\(\sum_{v} Cost(v)p(v)\)</span> is the average cost per population unit, if we treat everyone (all segments). Similarly, <span class="math inline">\(\sum_{v \in T} Cost(v)p(v)\)</span> is the average cost per population unit, if we only treat some subset of segments <span class="math inline">\(T\)</span>.</p>
<p>This use case can again be formulated in terms of the <em>knapsack problem</em>, where the goal is find the set of segments <span class="math inline">\(T\subseteq \{v: CATE(v) &gt; 0\}\)</span> that maximizes <span class="math inline">\(\sum_{v\in T} CATE(v)\)</span>, subject to the constraint <span class="math inline">\(\sum_{v\in T} Cost(v) p(v) \leq \text{budget}\)</span>. The previous example is a special case with a fixed cost <span class="math inline">\(Cost(v)=c\)</span> for all segments.</p>
<p>The data structure and calls to <code>sherlock_calculate</code> are slightly different in this example. The data should have a column for the treatment cost for a unit.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">data_example_with_cost</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">data_example_with_cost</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt;   num_devices is_p2plus is_newmarket baseline_ltv baseline_viewing treatment</span>
<span class="co">#&gt; 1           2         1            0    0.3500025       0.01014789         0</span>
<span class="co">#&gt; 2           4         0            0    0.8144417       1.56213812         1</span>
<span class="co">#&gt; 3           3         0            1    0.0000000       0.41284605         0</span>
<span class="co">#&gt; 4           5         1            0    0.0000000       0.00000000         0</span>
<span class="co">#&gt; 5           5         1            0    0.0000000       0.71454993         1</span>
<span class="co">#&gt; 6           1         1            0    0.0000000       0.58507617         0</span>
<span class="co">#&gt;   outcome_viewing     cost</span>
<span class="co">#&gt; 1       0.3500025 1.505074</span>
<span class="co">#&gt; 2       5.0144417 2.781069</span>
<span class="co">#&gt; 3       1.0000000 2.786524</span>
<span class="co">#&gt; 4       0.0000000 3.518043</span>
<span class="co">#&gt; 5      -3.0000000 3.564960</span>
<span class="co">#&gt; 6       0.0000000 1.292538</span></code></pre></div>
<p>When calling the <code>sherlock_calculate</code> function, we need to add the argument <code>treatment_cost</code> to specify the column for the treatment cost in the data.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sherlock_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sherlock_calculate.html">sherlock_calculate</a></span><span class="op">(</span>
  data_from_case <span class="op">=</span> <span class="va">data_example_with_cost</span>,
  baseline <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"num_devices"</span>, <span class="st">"is_p2plus"</span>, <span class="st">"is_newmarket"</span>, <span class="st">"baselin_ltv"</span>,
               <span class="st">"baseline_viewing"</span><span class="op">)</span>,
  exposure <span class="op">=</span> <span class="st">"treatment"</span>,
  outcome <span class="op">=</span> <span class="st">"outcome_viewing"</span>,
  segment_by <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"num_devices"</span>, <span class="st">"is_p2plus"</span><span class="op">)</span>,
  treatment_cost <span class="op">=</span> <span class="st">"cost"</span>,
  cv_folds <span class="op">=</span> <span class="fl">5L</span>,
  ps_learner <span class="op">=</span> <span class="va">ps_learner_spec</span>,
  or_learner <span class="op">=</span> <span class="va">or_learner_spec</span>,
  cate_learner <span class="op">=</span> <span class="va">cate_learner_spec</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sherlock_results</span><span class="op">)</span>
<span class="co">#&gt;     num_devices is_p2plus segment_proportion    cate  lwr_ci  upr_ci std_err</span>
<span class="co">#&gt;  1:           1         0             0.0392  0.4202  0.1863  0.6542 0.11936</span>
<span class="co">#&gt;  2:           1         1             0.0862  1.9959  1.8509  2.1410 0.07402</span>
<span class="co">#&gt;  3:           2         0             0.0718 -0.4709 -0.6407 -0.3011 0.08663</span>
<span class="co">#&gt;  4:           2         1             0.1752  2.8154  2.7124  2.9184 0.05255</span>
<span class="co">#&gt;  5:           3         0             0.0764 -1.2384 -1.4045 -1.0722 0.08476</span>
<span class="co">#&gt;  6:           3         1             0.1796  3.5527  3.4428  3.6627 0.05611</span>
<span class="co">#&gt;  7:           4         0             0.0728  4.4947  4.3152  4.6741 0.09158</span>
<span class="co">#&gt;  8:           4         1             0.1814 -2.0596 -2.1647 -1.9546 0.05360</span>
<span class="co">#&gt;  9:           5         0             0.0328  5.5360  5.2730  5.7990 0.13417</span>
<span class="co">#&gt; 10:           5         1             0.0846 -2.7538 -2.9083 -2.5993 0.07884</span>
<span class="co">#&gt;     avg_treatment_cost</span>
<span class="co">#&gt;  1:              1.384</span>
<span class="co">#&gt;  2:              1.846</span>
<span class="co">#&gt;  3:              1.840</span>
<span class="co">#&gt;  4:              2.347</span>
<span class="co">#&gt;  5:              2.340</span>
<span class="co">#&gt;  6:              2.835</span>
<span class="co">#&gt;  7:              2.821</span>
<span class="co">#&gt;  8:              3.329</span>
<span class="co">#&gt;  9:              3.296</span>
<span class="co">#&gt; 10:              3.845</span></code></pre></div>
<p>In addition to the segment proportion in the population, its estimated CATE and associated confidence intervals and standard error, the default print out (or a call <code>attr(sherlock_results, "summary")</code> ) now also provides <code>avg_treatment_cost</code>, which is the average treatment cost <span class="math inline">\(Cost(v)\)</span> of treating a unit in each segment.</p>
<p>Note that the cost constraint of “average cost per population unit” is expressed in terms of <code>avg_treatment_cost*segment_proportion</code> <span class="math inline">\(=Cost(v)p(v)\)</span>:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## if treating all units, then the average cost per population unit is 2.687:</span>
<span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">sherlock_results</span>, <span class="st">"summary"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">summarize</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">avg_treatment_cost</span> <span class="op">*</span> <span class="va">segment_proportion</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;   sum(avg_treatment_cost * segment_proportion)</span>
<span class="co">#&gt; 1                                     2.687224</span>

<span class="co"># if treating only those with cate &gt; 0, then the average cost is 1.44:</span>
<span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">sherlock_results</span>, <span class="st">"summary"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">cate</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">summarize</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">avg_treatment_cost</span> <span class="op">*</span> <span class="va">segment_proportion</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;   sum(avg_treatment_cost * segment_proportion)</span>
<span class="co">#&gt; 1                                     1.447183</span></code></pre></div>
<p>Whenever we choose not to treat certain segments, those units incur 0 cost. Thus, the average cost per population unit is lowered.</p>
<p>To find the segments to treat, we will again use the segmentation function <code><a href="../reference/cost_funs.html">cost_knapsack()</a></code>. The argument <code>use_segment_treatment_cost=TRUE</code> specifies the <code>avg_treatment_cost</code> per segment (<span class="math inline">\(Cost(v)\)</span>) must be used in conjunction with <code>segment_proportion</code> (<span class="math inline">\(p(v)\)</span>), to evaluate the cost constraints. The argument <code>budget</code> specifies the cap on the average treatment cost per population unit: <span class="math inline">\(\sum_{v\in T} Cost(v) p(v) \leq \text{budget}\)</span>. Similar to before, <code>type=inferential</code> means we use hypothesis testing to determine <span class="math inline">\(CATE(v) &gt; 0\)</span>.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sherlock_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/watson_segment.html">watson_segment</a></span><span class="op">(</span>
  <span class="va">sherlock_results</span>,
  segment_fun <span class="op">=</span> <span class="va">cost_knapsack</span>,
  budget <span class="op">=</span> <span class="fl">1</span>,
  use_segment_treatment_cost <span class="op">=</span> <span class="cn">TRUE</span>,
  type <span class="op">=</span> <span class="st">"inferential"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sherlock_results</span><span class="op">)</span>
<span class="co">#&gt;     num_devices is_p2plus segment_proportion    cate  lwr_ci  upr_ci std_err</span>
<span class="co">#&gt;  1:           1         0             0.0392  0.4202  0.1863  0.6542 0.11936</span>
<span class="co">#&gt;  2:           1         1             0.0862  1.9959  1.8509  2.1410 0.07402</span>
<span class="co">#&gt;  3:           2         0             0.0718 -0.4709 -0.6407 -0.3011 0.08663</span>
<span class="co">#&gt;  4:           2         1             0.1752  2.8154  2.7124  2.9184 0.05255</span>
<span class="co">#&gt;  5:           3         0             0.0764 -1.2384 -1.4045 -1.0722 0.08476</span>
<span class="co">#&gt;  6:           3         1             0.1796  3.5527  3.4428  3.6627 0.05611</span>
<span class="co">#&gt;  7:           4         0             0.0728  4.4947  4.3152  4.6741 0.09158</span>
<span class="co">#&gt;  8:           4         1             0.1814 -2.0596 -2.1647 -1.9546 0.05360</span>
<span class="co">#&gt;  9:           5         0             0.0328  5.5360  5.2730  5.7990 0.13417</span>
<span class="co">#&gt; 10:           5         1             0.0846 -2.7538 -2.9083 -2.5993 0.07884</span>
<span class="co">#&gt;     threshold avg_treatment_cost test_stat       pval   pval_adj rule</span>
<span class="co">#&gt;  1:         0              1.384     3.520  2.154e-04  3.590e-04    0</span>
<span class="co">#&gt;  2:         0              1.846    26.965 1.882e-160 3.764e-160    1</span>
<span class="co">#&gt;  3:         0              1.840    -5.436  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  4:         0              2.347    53.576  0.000e+00  0.000e+00    0</span>
<span class="co">#&gt;  5:         0              2.340   -14.610  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  6:         0              2.835    63.321  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt;  7:         0              2.821    49.081  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt;  8:         0              3.329   -38.428  1.000e+00  1.000e+00    0</span>
<span class="co">#&gt;  9:         0              3.296    41.260  0.000e+00  0.000e+00    1</span>
<span class="co">#&gt; 10:         0              3.845   -34.928  1.000e+00  1.000e+00    0</span>

<span class="co">## constraint satisfied? resulting average cost per population unit:</span>
<span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">sherlock_results</span>,<span class="st">'summary'</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">rule</span><span class="op">==</span><span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">summarize</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">avg_treatment_cost</span><span class="op">*</span><span class="va">segment_proportion</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;   sum(avg_treatment_cost * segment_proportion)</span>
<span class="co">#&gt; 1                                    0.9818078</span></code></pre></div>
<p>The resulting cost constraint would be satisfied if we followed this segment-rule based strategy. We also saw earlier that if we treated all units the resulting cost per unit would be ~ 2.69.</p>
<p>In addition to lower cost, the segment-rule based strategy also yields better metric outcome, compared to treating all units:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/mycroft_assess.html">mycroft_assess</a></span><span class="op">(</span>
  <span class="va">sherlock_results</span>,
  param_type <span class="op">=</span> <span class="st">"ote"</span>
<span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">print</span>
<span class="co">#&gt; Counterfactual Mean Outcome If All Get Treatment</span>
<span class="co">#&gt;   Parameter Estimate:  2.266 </span>
<span class="co">#&gt;   95% Conf Interval: (2.184, 2.349) </span>
<span class="co">#&gt;   Standard Error:  0.04212 </span>
<span class="co">#&gt; Counterfactual Mean Outcome If All Get Control</span>
<span class="co">#&gt;   Parameter Estimate:  1.169 </span>
<span class="co">#&gt;   95% Conf Interval: (1.138, 1.201) </span>
<span class="co">#&gt;   Standard Error:  0.01596 </span>
<span class="co">#&gt; Counterfactual Mean Outcome If Treat Based on Segment Rule</span>
<span class="co">#&gt;   Parameter Estimate:  2.492 </span>
<span class="co">#&gt;   95% Conf Interval: (2.431, 2.554) </span>
<span class="co">#&gt;   Standard Error:  0.03124 </span>
<span class="co">#&gt; Optimal Treatment Effect: Treat based on Segment Rule vs. All Get Treatment</span>
<span class="co">#&gt;   Parameter Estimate:  0.2262 </span>
<span class="co">#&gt;   95% Conf Interval: (0.1672, 0.2852) </span>
<span class="co">#&gt;   Standard Error:  0.03011 </span>
<span class="co">#&gt; Optimal Treatment Effect: Treat based on Segment Rule vs All Get Control</span>
<span class="co">#&gt;   Parameter Estimate:  1.323 </span>
<span class="co">#&gt;   95% Conf Interval: (1.265, 1.381) </span>
<span class="co">#&gt;   Standard Error:  0.02966</span></code></pre></div>
</div>
</div>
</div>
<div id="appendix-the-methodology-behind-sherlock" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#appendix-the-methodology-behind-sherlock" class="anchor"></a>Appendix: The methodology behind <code>sherlock</code>
</h1>
<p>Let * <span class="math inline">\(A\)</span> = treatment, 0 for control, 1 treatment. Consider binary for now. * <span class="math inline">\(Y\)</span> = metric of interest. Continuous or binary. * <span class="math inline">\(W\)</span> = baseline covariates. These include covariates used to adjust for confounder bias (if non-AB) and/or to reduce variance. May be continuous or discrete. * <span class="math inline">\(V\subseteq W\)</span> = a set of segment dimensions/covariates, and <span class="math inline">\(\mathcal{V}\)</span> its outcome space. A realization <span class="math inline">\(V=v\)</span> represents a segment of users. * For a segment <span class="math inline">\(V=v\)</span>, <span class="math inline">\(CATE(v) = E[E(Y|A=1,W)-E(Y|A=0,W)|V=v)]\)</span> is the <strong>Conditional Average Treatment Effect (CATE)</strong> on this segment.</p>
<p>We want to know which segments of users would benefit from treatment. This benefit can be:</p>
<ol style="list-style-type: lower-alpha">
<li>In absolute terms. Specifically, the goal here is to identify segments <span class="math inline">\(T=\{v\in\mathcal{V}: CATE(v) &gt; \text{threshold}\}\)</span> for some user-specified benefit threshold.</li>
<li>Subject to cost or side-effects constraints. This can be formulated in terms of a constrained optimization with respect to CATE: Identify segments <span class="math inline">\(T\subseteq \mathcal{V}\)</span> so to maximize <span class="math display">\[\phi= \sum_{v \in T} E[  E(Y|A=1, W)
| V= v] p(v) +\sum_{v \notin T} E[  E(Y|A=0, W) | V= v]p(v)\]</span> subject to the constraint <span class="math inline">\(\sum_{v \in T} Cost(v) p(v) \leq \text{budget}\)</span>, where the cost function <span class="math inline">\(Cost(v)\geq 0\)</span> and the <span class="math inline">\(\text{budget}\)</span> constraint are user-specified. In other words, we seek to learn the ‘should-treat’ segments <span class="math inline">\(T\)</span>, such that if we were to treat the population based on whether or not they belong to any of these segments in <span class="math inline">\(T\)</span>, then the resulting population-level outcome <span class="math inline">\(\phi\)</span> is maximized, while the average cost per population unit is capped at the desired level. This can be reformulated in terms of the <em>knapsack problem</em> of finding <span class="math inline">\(T\subseteq \{v: CATE(v)&gt;0\}\)</span> which maximizes <span class="math inline">\(\phi_2=\sum_{v\in V} CATE(v)\)</span> subject to the constraint <span class="math inline">\(\sum_{v \in T} Cost(v) p(v) \leq \text{budget}\)</span>.</li>
</ol>
<!-- 2. How do we quantify the HTE across the segments? We consider this a
separate but related question to segment discovery, where one wishes to
quantify HTE across the segments defined by a given set of segment dimensions.
We can formulate this as learning a two-set partition of $\mathcal{V}$ to
maximize $HTE= \sum_{v \in T} CATE(v) p(v) -  \sum_{v \notin T} CATE(v) p(v)$.
In other words, it learns the maximal HTE range across the segments given by
these dimensions.--><p>Both of these questions can be framed in terms of classifying the segments based on some criterion on their CATE. Thus we largely divided the package into 3 modular tasks:</p>
<ol style="list-style-type: decimal">
<li>
<code>sherlock_calculate</code>: Estimating CATE.</li>
<li>
<code>watson_segment</code>: Learning the segmentation (i.e., which segments to treat).</li>
<li>
<code>mycroft_assess</code>: Evaluating the effectiveness of the resulting segmentation.</li>
</ol>
<p>The CATE and the effectiveness measures are implemented using sample splitting principles in CVTMLE (<span class="citation">Zheng and van der Laan (2010)</span>, <span class="citation">van der Laan and Luedtke (2015)</span>).</p>
<p>In <code>sherlock_calculate</code>: To estimate CATE, we first apply machine learning methods chosen by the user and sample splitting principles in CV-TMLE to estimate the outcome regression <span class="math inline">\(E(Y|A,W)\)</span> and the propensity score <span class="math inline">\(p(A|W)\)</span> (if non-AB data). Then, we use these nuisance parameter estimates to perform a double robust outcome transformation <span class="math inline">\(D=\frac{2A-1}{p(A|W)}[Y-E(Y|A,W)] + E(Y|1,W)-E(Y|0,W)\)</span>. We then regress this <span class="math inline">\(D\)</span> onto the segment dimensions <span class="math inline">\(V\)</span> using machine learning. This regression <span class="math inline">\(E(D|V)\)</span> allows us to compute out-of-sample double robust estimates of <span class="math inline">\(CATE(V)\)</span>, and the associated standard errors.</p>
<p>In <code>watson_segment</code>: The two classes of segment discovery problems require a determination of whether a segment <span class="math inline">\(v\)</span> satisfies <span class="math inline">\(CATE(v) &gt; \delta\)</span> for some constant <span class="math inline">\(\delta\)</span>. In problem a, <span class="math inline">\(\delta\)</span> is the threshold given by the user. In problem b, <span class="math inline">\(\delta=0\)</span>. By default, we implement this segment classification as an upper tail hypothesis testing problem (H1: <span class="math inline">\(CATE(v) &gt; \delta\)</span>; H0: <span class="math inline">\(CATE(v) \leq \delta\)</span>), controlling for false discovery rate in the multiple comparisons across the segments. For the cost constrained problems, the <code>knapsack</code> algorithm is applied on the segments that were determined to have <span class="math inline">\(CATE(v)&gt;0\)</span>.</p>
<p>In <code>mycroft_assess</code>: Once we learn this segmentation of the population into <span class="math inline">\(T\)</span> and its complement, we can evaluate how effectively it has achieved the segmentation goal. For example, we can estimate the population-level outcome under the optimal segment-rule treatment strategy. Specifically, this parameter is <span class="math inline">\(\psi_d = E[ E(Y|A=d(V), W)]\)</span>, where <span class="math inline">\(d(v) = I(v \in T)\)</span> assigns treatment to segments in <span class="math inline">\(T\)</span>, and assigns control otherwise. <span class="math inline">\(E(Y|A=d(V),W)\)</span> is the expected outcome in an individual if they followed their segment’s optimal treatment rule, and <span class="math inline">\(E[E(Y|A=d(V), W)]\)</span> is averaged over the population. <span class="math inline">\(\psi_d\)</span> can be contrasted with <span class="math inline">\(\psi_1 = E[E(Y|A=1, W)]\)</span>, the population outcome if all receive treatment, and <span class="math inline">\(\psi_0 = E[E(Y|A=0, W)]\)</span>, the population outcome if all receive control. <span class="math inline">\(\psi_d-\psi_1\)</span> and <span class="math inline">\(\psi_d-\psi_0\)</span> are both valid Optimal Treatment Effects, depending on what we consider as reference strategy. These are implemented in <code>mycroft_assess</code> with <code>param_type=ote</code>. Alternatively, we can consider treatment effects on the learn segment groups. <span class="math inline">\(\mu_{all} = E[ E(Y|A=1, W) - E(Y|A=0, W) ]\)</span> is the average treatment effect (treatment-all vs control-all) on the whole population. Similarly, <span class="math inline">\(\mu_{1} = E[ E(Y|A=1, W) - E(Y|A=0, W) | V \in T]\)</span> and <span class="math inline">\(\mu_{0} = E[ E(Y|A=1, W) - E(Y|A=0, W) | V \notin T]\)</span> are the average treatment effects among segments that are recommended treatment (<span class="math inline">\(v\in T\)</span>) and those that are not recommended (<span class="math inline">\(v\notin T\)</span>). And we can also contrast the HTE in these two segment groups <span class="math inline">\(\mu_{1}-\mu_{0}\)</span>. These are implemented in <code>mycroft_assess</code> with <code>param_type=hte</code>.</p>
<div id="assumptions-and-data-requirements" class="section level2">
<h2 class="hasAnchor">
<a href="#assumptions-and-data-requirements" class="anchor"></a>Assumptions and data requirements</h2>
<p>We make two standard assumptions in causal inference:</p>
<ul>
<li><p>There is sufficient variability of the treatment and control within each subgroup defined by the baseline covariates and by the segment dimensions. This means that we do not have a subgroup of users that rarely or never receive a specific treatment category.</p></li>
<li><p>Inferring causal effects outside of AB experiments rely on strong causal assumptions. For non-AB data, we make the standard implicit causal assumption that the data captures all the common causes between a unit’s treatment and the outcome of interest.</p></li>
</ul>
<p>Specific to the methodology we implemented, we also require each segment to have a moderate number of observations in the data (&gt; 50). This is to ensure that we can provide a standard error for CATE on each segment. In the absence of this requirement, we can still obtain point estimates of CATE and learn a desired segmentation, but would be unable to provide reliable statistical inference on CATE.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-Luedtke16b">
<p>Luedtke, Alex, and Mark van der Laan. 2016a. “Optimal Individualized Treatments in Resource-Limited Settings.” <em>International Journal of Biostatistics</em> 12 (1): 283–303. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6052884/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6052884/</a>.</p>
</div>
<div id="ref-Luedtke16a">
<p>———. 2016b. “Super-Learning of an Optimal Dynamic Treatment Rule.” <em>International Journal of Biostatistics</em> 12 (1): 305–32. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6056197/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6056197/</a>.</p>
</div>
<div id="ref-vdL15">
<p>van der Laan, Mark, and Alex Luedtke. 2015. “Targeted Learning of the Mean Outcome Under an Optimal Dynamic Treatment Rule.” <em>Journal of Causal Inference</em> 3 (1): 61–95. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4517487/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4517487/</a>.</p>
</div>
<div id="ref-vanderweele19">
<p>Vanderweele, Tyler, Alex Luedtke, Mark van der Laan, and Ronald Kessler. 2019. “Selecting Optimal Subgroups for Treatment Using Many Covariates.” <em>Epidemiology</em> 30 (3): 334–41. <a href="https://journals.lww.com/epidem/Fulltext/2019/05000/Selecting_Optimal_Subgroups_for_Treatment_Using.5.aspx">https://journals.lww.com/epidem/Fulltext/2019/05000/Selecting_Optimal_Subgroups_for_Treatment_Using.5.aspx</a>.</p>
</div>
<div id="ref-wzheng10">
<p>Zheng, Wenjing, and Mark van der Laan. 2010. “Asymptotic Theory of Cross-Validated Targeted Maximum Likelihood Estimation.” <a href="https://biostats.bepress.com/ucbbiostat/paper273/">https://biostats.bepress.com/ucbbiostat/paper273/</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Nima Hejazi, Wenjing Zheng, Netflix, Inc..</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
